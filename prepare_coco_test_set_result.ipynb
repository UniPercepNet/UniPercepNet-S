{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def41e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alan_khang/dev/YOLOF-MaskV2-mmcv\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b410b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import mmdet\n",
    "import mmcv\n",
    "import mmengine\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "\n",
    "from pycocotools.mask import encode as cvt_mask_to_rle\n",
    "from pycocotools.mask import decode as cvt_rle_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62bd8e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/alan_khang/Desktop/unipercepnet_v2/epoch_12.pth\n"
     ]
    }
   ],
   "source": [
    "config_file = './configs/unipercepnet_v2.py'\n",
    "ckpt_file = '/home/alan_khang/Desktop/unipercepnet_v2/epoch_12.pth'\n",
    "\n",
    "model = init_detector(config_file, checkpoint=ckpt_file, device='cuda:0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20288 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pycocotools.mask import encode as cvt_mask_to_rle\n",
    "from pycocotools.mask import decode as cvt_rle_to_mask\n",
    "\n",
    "annot_path = \"./datasets/coco2017/coco_test_annotations/image_info_test-dev2017.json\"\n",
    "img_dir = \"./datasets/coco2017/coco_test_dev2017/coco_test2017\"\n",
    "annot_info_file = annot_path\n",
    "\n",
    "results_file = './output/coco_test_infer/detections_test-dev2017_regnetx_tood_1x_results.json'\n",
    "\n",
    "if os.path.exists(results_file):\n",
    "    os.remove(results_file)\n",
    "else:\n",
    "    fp = open(results_file, 'w')\n",
    "    fp.close()\n",
    "\n",
    "with open(annot_info_file, 'r') as file:\n",
    "    annots = json.load(file)\n",
    "\n",
    "num_imgs = len(annots['images'])\n",
    "\n",
    "annType = ['segm','bbox','keypoints']\n",
    "annType = annType[0]\n",
    "\n",
    "coco_ids = [\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, \n",
    "    21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "    41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, \n",
    "    59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, \n",
    "    80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
    "\n",
    "def convert_bbox_xyxy_to_xywh(x1, y1, x2, y2):\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return [x1, y1, w, h]\n",
    "\n",
    "with open(results_file, 'w') as file:\n",
    "    for i, image in enumerate(tqdm(annots['images'])):\n",
    "\n",
    "        if i == 0:\n",
    "            file.write('[')\n",
    "        else:\n",
    "            file.write(',')\n",
    "\n",
    "        file_name = image['file_name']\n",
    "        image_id = image['id']\n",
    "        results_each_img = []\n",
    "\n",
    "        if (file_name is None) or (image_id is None):\n",
    "            print('file_name or image_id is null')\n",
    "\n",
    "        image_path = os.path.join(img_dir, file_name)\n",
    "        img = mmcv.imread(image_path, channel_order='bgr')\n",
    "        predictions = inference_detector(model, img)\n",
    "\n",
    "        output = predictions.pred_instances\n",
    "        pred_boxes = output.bboxes.to('cpu')\n",
    "        pred_masks = output.masks.to('cpu')\n",
    "        pred_cls_ids = output.labels.to('cpu')\n",
    "        pred_confs = output.scores.to('cpu')\n",
    "        assert pred_boxes.size()[0] == pred_masks.size()[0] == pred_cls_ids.size()[0] == pred_confs.size()[0]\n",
    "\n",
    "        for j in range(pred_boxes.size()[0]):\n",
    "            box, mask, model_cls_id, conf = pred_boxes[j], pred_masks[j], pred_cls_ids[j], pred_confs[j]\n",
    "            pred_coco_id = coco_ids[model_cls_id.item()]\n",
    "            result = {\"image_id\": image_id,\n",
    "                      \"category_id\": pred_coco_id,\n",
    "                      \"score\": round(conf.item(), 3)}\n",
    "\n",
    "            if annType == \"bbox\":\n",
    "                result[\"bbox\"] = convert_bbox_xyxy_to_xywh(*box.tolist())\n",
    "            elif annType == 'segm':\n",
    "                mask = mask.numpy().astype(np.uint8)\n",
    "                mask = np.asfortranarray(mask)\n",
    "                rle = cvt_mask_to_rle(mask)\n",
    "                rle[\"counts\"] = rle[\"counts\"].decode()\n",
    "                result[\"segmentation\"] = rle\n",
    "            else:\n",
    "                print(\"Wronge annType\")\n",
    "\n",
    "            results_each_img.append(result)\n",
    "\n",
    "        # Write result to file\n",
    "        file.write(json.dumps(results_each_img)[1:-1])\n",
    "\n",
    "        if i == num_imgs - 1:\n",
    "            file.write(']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba94ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/bdd100k/labels_coco/ins_seg/ins_seg_val_coco.json', 'r') as f:\n",
    "    val_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'categories', 'images', 'annotations'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69278dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'pedestrian'},\n",
       " {'id': 2, 'name': 'rider'},\n",
       " {'id': 3, 'name': 'car'},\n",
       " {'id': 4, 'name': 'truck'},\n",
       " {'id': 5, 'name': 'bus'},\n",
       " {'id': 6, 'name': 'train'},\n",
       " {'id': 7, 'name': 'motorcycle'},\n",
       " {'id': 8, 'name': 'bicycle'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_annotations['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24488822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unipercepnet_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
